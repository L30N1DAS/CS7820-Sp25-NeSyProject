{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a81a3a0-9dff-4369-8950-85d1b4057c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an experienced instructor for a graduate-level data science course in an engineering program. \n",
    "You have experience creating assessments for the course. Your task is to assess the question based on certain evaluation criteria given. Output only the answer and nothing else and only from the options\n",
    "\n",
    "Evaluation Criteria:\n",
    " - Understandable: Could you understand what the question is asking? Please check if the question is composed in such a way that the question can be comprehended easily; Options: yes, no\n",
    " - TopicRelated: Is the question related to the course topic given? Please check if the question pertains directly to the key themes or concepts of the given course topic; Options: yes, no, NA\n",
    " - Grammatical: Is the question grammatically well-formed? Please check if the question adheres to the rules of English grammar; Options: yes, no, NA\n",
    " - Clear: Is it clear what the question asks for? Please check if the phrasing of the question leaves any doubt about what is being asked. Also check if there's vagueness in the making it difficult to answer the question; Options: yes, more_or_less, no, NA\n",
    " - Rephrase: Could you rephrase the question to make it clearer and error-free? Please check if this question, as it is posed, can be reworded to improve clarity or correct errors while preserving its original meaning. If your answer is yes, rephrase the question; Options: yes, no, NA\n",
    " - Answerable: Can students answer the question with the information or context provided within? Please check if the question is answerable using the knowledge that the students are expected to have from the course material on the topic provided within the question itself. The course curriculum is a standard graduate-level data science course curriculum; Options: yes, no, NA\n",
    " - Central: Do you think being able to answer the question is important to work on the course topic given? Please check if answering the question requires an understanding of the key concepts that are critical to the subject matter; Options: yes, no, NA\n",
    " - WouldYouUseIt: If you were a teacher teaching the course topic, would you use this question or the rephrased version in the course? Please check if you would consider the question to be of practical value for teaching and learning, and if it is something that would be chosen for inclusion in course materials or assessments; Options: yes, maybe, no, NA\n",
    " - SkillLevel: What is the Bloomâ€™s skill associated with the question? This should be aligned with the complexity and type of cognitive process assessed in the question, from simple recall of facts (remember) to more complex tasks like synthesizing new ideas (create); Options: remember, understand, apply, analyze, evaluate, create, NA\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87ca399-3077-4c0c-b0ca-f457cb9c2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_template = \"\"\"\n",
    "Please make sure you read and understand the following content and instructions carefully. Evaluate it according to the instructions.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Course topic: {topic}\n",
    "\n",
    "Evaluation instructions: {Hierarchical_evaluation_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e5634c-99b7-45b1-b91d-d12405f13ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Understandable\", \"TopicRelated\", \"Grammatical\", \"Clear\", \"Rephrase\", \"Answerable\", \"Central\", \"WouldYouUseIt\", \"SkillLevel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9a23d6-4d07-423d-8b9b-99503629bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_prompt_template(template_text, values_dict):\n",
    "    for key, value in values_dict.items():\n",
    "        if value is None:\n",
    "            value = \"None\"\n",
    "        template_text = template_text.replace(f\"{{{key}}}\", value)\n",
    "    return template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a4d1bd-e021-40c8-8378-fb217b8824bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = [\n",
    "    \"Decision Tree Models\",\n",
    "    \"Training, Validation, and Testing of Machine Learning Models\",\n",
    "    \"Gradient Boosted Tree Models\",\n",
    "    \"Linear Regression, Logistic Regression, and Multilayer Perceptron\",\n",
    "    \"Stochastic Gradient Descent\",\n",
    "    \"Backpropagation\",\n",
    "    \"Foundations of Computer Vision and Convolutional Neural Networks\",\n",
    "    \"Transfer Learning for Computer Vision\",\n",
    "    \"Image Segmentation and Object Detection\",\n",
    "    \"Data Pre-processing for Natural Language Processing Tasks\",\n",
    "    \"Bag of Words Approach and Word Embedding\",\n",
    "    \"Attention Mechanism in Transformers\",\n",
    "    \"Neural Machine Translation using Transformers\",\n",
    "    \"Encoder, Decoder, and Sequence-to-Sequence Transformers\",\n",
    "    \"Pretraining, Finetuning, and Reinforcement Learning with Human Feedback\",\n",
    "    \"Prompt Engineering and Chain of Thought Prompting\",\n",
    "    \"Natural Language Processing Tasks and Transformer Architectures Used for the Tasks\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feecd045-2270-4a2d-a686-8e890b4d80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_cell_value(ws, cell):\n",
    "    # Check if the cell is part of a merged range\n",
    "    for merged_range in ws.merged_cells.ranges:\n",
    "        if cell.coordinate in merged_range:\n",
    "            # Return the value from the top-left cell of the merged range\n",
    "            return ws.cell(merged_range.min_row, merged_range.min_col).value\n",
    "    return cell.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fa5095-28fd-4dc9-ba9b-629f42c07e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_multi_task_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Cleans a list of 9 LLM outputs by checking the beginning of each response\n",
    "    against predefined valid options for each task. Only exact matches with optional\n",
    "    trailing punctuation are accepted.\n",
    "\n",
    "    Parameters:\n",
    "    - outputs (list of str): Raw outputs from the LLM for 9 tasks.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: Cleaned outputs with valid labels or \"Did not answer\".\n",
    "    \"\"\"\n",
    "    if len(outputs) != 9:\n",
    "        raise ValueError(\"Expected exactly 9 outputs.\")\n",
    "\n",
    "    valid_options = [\n",
    "        [\"yes\", \"no\"],  # 1\n",
    "        [\"yes\", \"no\", \"na\"],  # 2\n",
    "        [\"yes\", \"no\", \"na\"],  # 3\n",
    "        [\"yes\", \"more_or_less\", \"no\", \"na\"],  # 4\n",
    "        [\"yes\", \"no\", \"na\"],  # 5\n",
    "        [\"yes\", \"no\", \"na\"],  # 6\n",
    "        [\"yes\", \"no\", \"na\"],  # 7\n",
    "        [\"yes\", \"maybe\", \"no\", \"na\"],  # 8\n",
    "        [\"remember\", \"understand\", \"apply\", \"analyze\", \"evaluate\", \"create\", \"na\"],  # 9\n",
    "    ]\n",
    "\n",
    "    cleaned_outputs = []\n",
    "    for output, options in zip(outputs, valid_options):\n",
    "        output_lower = output.lower().strip()[:min(100,len(output))]\n",
    "\n",
    "        # Extract the first few words (in case it's a phrase like \"more_or_less\")\n",
    "        # Strip common trailing punctuation for matching\n",
    "        first_part = re.split(r'\\s|[.,!?]', output_lower)[0].strip(\",.!?\")\n",
    "\n",
    "        matched = None\n",
    "        for opt in options:\n",
    "            if first_part == opt:\n",
    "                matched = opt\n",
    "                break\n",
    "\n",
    "        cleaned_outputs.append(matched if matched else \"Did not answer\")\n",
    "\n",
    "    return cleaned_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a59ae941-7e40-4004-97e6-3a616997b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Load the workbook\n",
    "workbook_path = 'Questions_generated.xlsx'  # Replace with your actual file path\n",
    "wb = openpyxl.load_workbook(workbook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a091bc7a-1399-463d-9042-38e55785bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /root/.local/lib/python3.10/site-packages (1.69.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/.local/lib/python3.10/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/.local/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11443ebf-e2b3-4aa1-b90f-f615c6dd7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block: Setup OpenAI API and GitHub Repo Access\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = None\n",
    "# Function to set OpenAI API Key\n",
    "def set_openai_api_key(api_key):\n",
    "  global client\n",
    "  client = OpenAI(api_key=api_key)\n",
    "  openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d8ea8-2b6d-4b81-9b3f-5c91aa23c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get OpenAI API Key\n",
    "key = \"<YOUR_OPENAI_API_KEY>\"  # Replace with your actual OpenAI API key\n",
    "set_openai_api_key(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "979d12ab-71bd-4f20-9b98-5261deb7b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block: Send Prompt to OpenAI ChatGPT API\n",
    "def global_openai_api_call(prompt, engine='gpt-4o'):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "    # Call the OpenAI API to generate content\n",
    "    global client\n",
    "    temp_Client = client\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    try:\n",
    "      response = temp_Client.completions.create(\n",
    "        model=engine,\n",
    "        prompt=prompt,\n",
    "        temperature=0.1\n",
    "      )\n",
    "    except openai.APIError as e:\n",
    "      try:\n",
    "        response = client.chat.completions.create(\n",
    "          model=engine,\n",
    "          messages=messages\n",
    "          )\n",
    "        return response.choices[0].message.content.strip()\n",
    "      except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "      print(f\"Error: {e}\")\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a7440-0cb1-4a79-b371-76a47d5ab654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "model = \"gpt4o\"\n",
    "# Iterate over all sheets in the workbook\n",
    "for sheet_name in wb.sheetnames:\n",
    "    ws = wb[sheet_name]\n",
    "    print(f\"\\nSheet: {sheet_name}\")\n",
    "    with open(f\"{sheet_name}_{model}.csv\", \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        for row in ws.iter_rows(min_row=2, max_col=4, max_row = 715):\n",
    "            index = row[0].value  \n",
    "            prompt = row[1].value \n",
    "            col_b_cell = row[1] if len(row) > 1 else None  \n",
    "            prompt = get_merged_cell_value(ws, col_b_cell) if col_b_cell else None\n",
    "            question = row[3].value  \n",
    "            topic = [topic for topic in TOPICS if topic in prompt][0]\n",
    "            print(f\"Index {index} Topic: {topic}\")\n",
    "            temp = []\n",
    "            for metric in metrics:\n",
    "                template_values = {\n",
    "                    \"question\": question,\n",
    "                    \"topic\": topic,\n",
    "                    \"Hierarchical_evaluation_description\": f\"Evaluate only the metric {metric}\"\n",
    "                }\n",
    "                filled_prompt = fill_prompt_template(user_prompt_template, template_values)\n",
    "                temp.append(global_openai_api_call(filled_prompt, engine='gpt-4o'))\n",
    "            temp = clean_multi_task_outputs(temp)\n",
    "            writer.writerow(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
